{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091d4f1e-9c14-4503-8e4c-9f731b89573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # Import the Computer vision library (OpenCV)\n",
    "import numpy as np # Import the Scientific computing library Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db16b752-b13f-4b09-9405-a416a65cbc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the video file is in the same directory as your code\n",
    "\n",
    "filename = 'Drive in Karlsruhe.mp4'\n",
    "file_size = (1280,720) # check that on files details : 1280x720 HD mp4\n",
    "\n",
    "# We want to save the output to a video file\n",
    "\n",
    "output_filename = 'Drive in Karlsruhe_obj_detection.mp4'\n",
    "output_frames_per_second = 20.0\n",
    " \n",
    "RESIZED_DIMENSIONS = (300, 300) # Dimensions that SSD requires for the training\n",
    "IMG_NORM_RATIO = 0.007843 # In grayscale a pixel can range between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c3a279-f31b-4f52-981a-df2b013cc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained neural network (Caffe Framework)\n",
    "\n",
    "neural_network = cv2.dnn.readNetFromCaffe('MobileNetSSD_deploy.prototxt.txt', \n",
    "        'MobileNetSSD_deploy.caffemodel')\n",
    " \n",
    "# List of categories and classes\n",
    "categories = { 0: 'background', 1: 'aeroplane', 2: 'bicycle', 3: 'bird', \n",
    "               4: 'boat', 5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', \n",
    "               9: 'chair', 10: 'cow', 11: 'diningtable', 12: 'dog', \n",
    "              13: 'horse', 14: 'motorbike', 15: 'person', \n",
    "              16: 'pottedplant', 17: 'sheep', 18: 'sofa', \n",
    "              19: 'train', 20: 'tvmonitor'}\n",
    " \n",
    "classes =  [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "            \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \n",
    "           \"diningtable\",  \"dog\", \"horse\", \"motorbike\", \"person\", \n",
    "           \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# we create boundary boxes and utilizes those boxes to classify objects\n",
    "\n",
    "bbox_colors = np.random.uniform(255, 0, size=(len(categories), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40cc112a-5e81-4bc7-9b86-8ed534b021ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    " \n",
    "  # Load a video\n",
    "  cap = cv2.VideoCapture(filename)\n",
    " \n",
    "  # Create a VideoWriter object so we can save the video output\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  result = cv2.VideoWriter(output_filename,  \n",
    "                           fourcc, \n",
    "                           output_frames_per_second, \n",
    "                           file_size) \n",
    "     \n",
    "  # Process the video\n",
    "  while cap.isOpened():\n",
    "         \n",
    "    # Capture one frame at a time\n",
    "    success, frame = cap.read() \n",
    " \n",
    "    # Do we have a video frame? If true, proceed.\n",
    "    if success:\n",
    "         \n",
    "      # Capture the frame's height and width\n",
    "      (h, w) = frame.shape[:2]\n",
    " \n",
    "      # Create a blob. A blob is a group of connected pixels in a binary frame that share some common property (e.g. grayscale value)\n",
    "      # Preprocess the frame to prepare it for deep learning classification\n",
    "      frame_blob = cv2.dnn.blobFromImage(cv2.resize(frame, RESIZED_DIMENSIONS), \n",
    "                     IMG_NORM_RATIO, RESIZED_DIMENSIONS, 127.5)\n",
    "     \n",
    "      # Set the input for the neural network\n",
    "      neural_network.setInput(frame_blob)\n",
    " \n",
    "      # Predict the objects in the image\n",
    "      neural_network_output = neural_network.forward()\n",
    " \n",
    "      # Put the bounding boxes around the detected objects\n",
    "      for i in np.arange(0, neural_network_output.shape[2]):\n",
    "             \n",
    "        confidence = neural_network_output[0, 0, i, 2]\n",
    "     \n",
    "        # Confidence must be at least 30%, otherwise doesnt form a box nor detect the object       \n",
    "        if confidence > 0.30:\n",
    "                 \n",
    "          idx = int(neural_network_output[0, 0, i, 1])\n",
    " \n",
    "          bounding_box = neural_network_output[0, 0, i, 3:7] * np.array(\n",
    "            [w, h, w, h])\n",
    " \n",
    "          (startX, startY, endX, endY) = bounding_box.astype(\"int\")\n",
    " \n",
    "          label = \"{}: {:.2f}%\".format(classes[idx], confidence * 100) \n",
    "         \n",
    "          cv2.rectangle(frame, (startX, startY), (\n",
    "            endX, endY), bbox_colors[idx], 2)     \n",
    "                         \n",
    "          y = startY - 15 if startY - 15 > 15 else startY + 15    \n",
    " \n",
    "          cv2.putText(frame, label, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.5, bbox_colors[idx], 2)\n",
    "         \n",
    "      # We now need to resize the frame so its dimensions are equivalent to the dimensions of the original frame\n",
    "    \n",
    "      frame = cv2.resize(frame, file_size, interpolation=cv2.INTER_NEAREST)\n",
    " \n",
    "            # Write the frame to the output video file\n",
    "      result.write(frame)\n",
    "         \n",
    "    # No more video frames left\n",
    "    else:\n",
    "      break\n",
    "             \n",
    "  # Stop when the video is finished\n",
    "  cap.release()\n",
    "     \n",
    "  # Release the video recording and save it in the same folder\n",
    "  result.release()\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
